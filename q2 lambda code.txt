import json
import boto3
import logging
from datetime import datetime

# setup logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

s3_client = boto3.client('s3')
sns_client = boto3.client('sns')

SNS_TOPIC_ARN = 'arn:aws:sns:us-east-1:585056206710:daily-reports-alerts'  # replace with your ARN

def lambda_handler(event, context):
    try:
        # Parse S3 event
        for record in event['Records']:
            bucket = record['s3']['bucket']['name']
            key = record['s3']['object']['key']
            size = record['s3']['object'].get('size', 'Unknown')
            event_time = record['eventTime']

            # Log the details
            logger.info(f"New file uploaded: s3://{bucket}/{key}")
            logger.info(f"Size: {size} bytes | Upload time: {event_time}")

            # Prepare metadata message
            message = {
                "Bucket": bucket,
                "FileName": key,
                "Size (Bytes)": size,
                "UploadTime": event_time
            }

            # Publish message to SNS
            sns_client.publish(
                TopicArn=SNS_TOPIC_ARN,
                Message=json.dumps(message, indent=2),
                Subject="New Daily Report Uploaded"
            )

        return {"status": "success"}

    except Exception as e:
        logger.error(f"Error processing S3 event: {str(e)}")
        raise e

